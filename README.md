# Artefato de Intelig√™ncia Artificial para Televendas T√©cnico-Consultivas (TTC)

Este reposit√≥rio apresenta um **artefato acad√™mico de Intelig√™ncia Artificial**, desenvolvido como objeto de estudo do **Mestrado Acad√™mico em Administra√ß√£o da Universidade Feevale**, com foco na **Intelig√™ncia Comercial aplicada a Televendas T√©cnico-Consultivas (TTC)**.

O artefato materializa-se em um **pipeline completo de an√°lise autom√°tica de liga√ß√µes de vendas**, integrando:

* **Transcri√ß√£o autom√°tica de √°udio**
* **An√°lise sem√¢ntica via Modelos de Linguagem (LLM) em modo Zero-Shot**
* **Avalia√ß√£o estruturada baseada no m√©todo SPIN Selling (Rackham, 1988)**

O projeto foi concebido para atender simultaneamente a **rigor cient√≠fico**, **aplicabilidade organizacional** e **reprodutibilidade metodol√≥gica**, respeitando princ√≠pios de **seguran√ßa, √©tica e uso respons√°vel de dados**.

---

## Contexto Acad√™mico

Este artefato √© resultado do:

**Mestrado Acad√™mico em Administra√ß√£o ‚Äî Universidade Feevale**
**Linha de Pesquisa:** Inova√ß√£o para Competitividade

**T√≠tulo do Trabalho:**
*Desenvolvimento de um Artefato de Intelig√™ncia Artificial para Potencializar a Intelig√™ncia Comercial em Televendas T√©cnico-Consultivas*

O desenvolvimento segue os princ√≠pios da **Design Science Research (DSR)**, cujo objetivo √© criar um artefato √∫til, fundamentado teoricamente e valid√°vel em contexto organizacional real.

---

## O que √© TTC ‚Äî Televendas T√©cnico-Consultivas

**Televendas T√©cnico-Consultivas (TTC)** representam um modelo de vendas complexas no qual o contato telef√¥nico vai al√©m da abordagem comercial tradicional. O foco est√° em:

* diagn√≥stico estruturado do contexto do cliente
* compreens√£o t√©cnica do problema ou necessidade
* explora√ß√£o das implica√ß√µes e impactos do cen√°rio atual
* constru√ß√£o expl√≠cita de valor antes da proposi√ß√£o de solu√ß√£o

Nesse modelo, o vendedor atua como **consultor**, conduzindo a conversa de forma anal√≠tica e orientada √† decis√£o.

O m√©todo **SPIN Selling**, proposto por **Neil Rackham (1988)**, estrutura esse processo em quatro fases:

* Situa√ß√£o
* Problema
* Implica√ß√£o
* Necessidade‚ÄìBenef√≠cio (Need-Payoff)

Este projeto utiliza Intelig√™ncia Artificial para **avaliar objetivamente a qualidade dessas intera√ß√µes**, reduzindo a depend√™ncia exclusiva de avalia√ß√µes humanas subjetivas.

---

## Vis√£o Geral do Funcionamento do Artefato

O artefato opera por meio de um fluxo local em Windows, com execu√ß√£o manual do pipeline:

1. Transcri√ß√£o de √°udio (gera√ß√£o de TXT e JSON)
2. An√°lise SPIN via LLM em modo Zero-Shot (gera√ß√£o de Excel)

---

## Arquitetura do Artefato

O sistema foi constru√≠do sobre dois pilares fundamentais:

1. **Transcri√ß√£o de √Åudio**
   Convers√£o de chamadas telef√¥nicas (WAV) em texto estruturado (TXT) e metadados (JSON).

2. **An√°lise Sem√¢ntica via LLM (Zero-Shot)**
   Classifica√ß√£o autom√°tica das falas segundo as fases do SPIN Selling, sem treinamento supervisionado, com gera√ß√£o de planilhas Excel para auditoria e uso organizacional.

---

## Requisitos T√©cnicos Obrigat√≥rios

* **Python 3.11** (obrigat√≥rio)
* Sistema Operacional: **Windows**
* Processador: CPU
* **Ollama instalado e em execu√ß√£o localmente (obrigat√≥rio)**

‚ö†Ô∏è **Este projeto N√ÉO utiliza VPS para execu√ß√£o local.**
‚ö†Ô∏è **O script 02 depende obrigatoriamente do Ollama local (qwen14b).**

---

# üöÄ Como Rodar o Projeto (Guia Completo ‚Äî Iniciantes e Avan√ßados)

Esta se√ß√£o explica, passo a passo e de forma did√°tica, como executar o projeto **localmente no Windows**, utilizando **PowerShell** (e, opcionalmente, **VS Code**), no fluxo **01 ‚Üí 02**.

O texto foi escrito assumindo que o leitor nunca programou, nunca usou PowerShell e n√£o tem familiaridade com ambientes t√©cnicos.

> Aviso fundamental:
> Se o **Ollama** n√£o estiver ativo, o projeto n√£o executa corretamente a etapa **02_zeroshot.py**.
> O fluxo local **n√£o utiliza VPS**.

---

## üìå Antes de come√ßar (obrigat√≥rio)

Antes de rodar o projeto, instale as ferramentas abaixo. Todas s√£o gratuitas.

### 1) Python 3.11 (obrigat√≥rio)

O Python √© a linguagem usada no projeto.

Link oficial (Python 3.11):
[https://www.python.org/downloads/release/python-3110/](https://www.python.org/downloads/release/python-3110/)

Durante a instala√ß√£o:

* Marque a op√ß√£o **Add Python to PATH**
* Conclua a instala√ß√£o

Como confirmar no PowerShell:

```powershell
py -3.11 --version
```

Resultado esperado (exemplo):

```
Python 3.11.x
```

---

### 2) Git (obrigat√≥rio para clonar o reposit√≥rio)

O Git √© usado para baixar o projeto do GitHub.

Link oficial:
[https://git-scm.com/downloads](https://git-scm.com/downloads)

Como confirmar no PowerShell:

```powershell
git --version
```

---

### 3) Ollama (obrigat√≥rio para a etapa 02)

O Ollama √© o motor local de LLM usado pela etapa 02.

Link oficial:
[https://ollama.com/download](https://ollama.com/download)

Como confirmar no PowerShell:

```powershell
ollama --version
```

Como iniciar o Ollama no Windows (passo obrigat√≥rio):

1. Abra **uma segunda janela** do PowerShell.
2. Execute:

```powershell
ollama serve
```

Essa janela deve permanecer aberta enquanto voc√™ estiver executando a etapa 02.

Modelo obrigat√≥rio (local):

* O script 02 utiliza o modelo configurado por vari√°vel de ambiente `OLLAMA_MODEL`.
* Valor esperado neste projeto: `qwen2.5:14b-instruct-q4_K_M`

Opcionalmente, voc√™ pode definir no PowerShell (na janela onde rodar√° o script 02):

```powershell
$env:OLLAMA_MODEL="qwen2.5:14b-instruct-q4_K_M"
```

---

## üíª O que √© terminal e PowerShell

PowerShell √© uma janela onde voc√™ digita comandos.

Para abrir no Windows:

1. Clique no menu Iniciar
2. Digite **PowerShell**
3. Abra o aplicativo

Durante este guia, todos os comandos devem ser executados no PowerShell.

---

## üì• Baixar o projeto (clonar via Git)

No PowerShell, execute:

```powershell
git clone https://github.com/pfcout/Artefato-de-I.A.-para-TTC.git
cd Artefato-de-I.A.-para-TTC
```

Observa√ß√£o:

* O comando `cd` significa ‚Äúentrar na pasta‚Äù.

---

## üß™ O que √© venv e por que usamos

Uma **venv** (ambiente virtual) √© um ambiente isolado do Python. Ela evita conflitos entre bibliotecas de projetos diferentes.

Este projeto utiliza **dois ambientes separados**, porque as depend√™ncias de transcri√ß√£o (01) s√£o diferentes das depend√™ncias de an√°lise (02):

* `.venv_transcricao` para o script 01
* `.venv_zeroshot` para o script 02

---

## ü™ü Regra importante: use duas janelas

Use sempre:

* Janela 1: comandos do projeto (01 e 02)
* Janela 2: manter o Ollama ativo com `ollama serve` (apenas para a etapa 02)

---

# üü¶ Etapa 01 ‚Äî Transcri√ß√£o local (scripts_base/01_transcricao.py)

## 1) Criar e ativar o ambiente da transcri√ß√£o

Na pasta do projeto, execute:

```powershell
py -3.11 -m venv .venv_transcricao
.\.venv_transcricao\Scripts\Activate.ps1
python -m pip install -U pip setuptools wheel
```

Quando ativado, o terminal mostrar√° algo como `(.venv_transcricao)` no in√≠cio da linha.

## 2) Instalar depend√™ncias da transcri√ß√£o

```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
python -m pip install -r requirements\requirements_transcricao.txt
```

## 3) Preparar os arquivos de entrada

Coloque seus √°udios `.wav` na pasta indicada pelo comando `--input_dir`.

Exemplo de pasta utilizada no projeto:

* `arquivos_audio/`

## 4) Executar a transcri√ß√£o (exemplo PowerShell com quebras de linha)

Exemplo para processar todos os `.wav` da pasta `arquivos_audio`:

```powershell
python .\scripts_base\01_transcricao.py `
  --input_dir ".\arquivos_audio" `
  --pattern "*.wav" `
  --recursive true `
  --model large-v3 `
  --language pt `
  --beam_size 5 `
  --vad_filter true `
  --device auto
```

Observa√ß√µes importantes:

* `--device auto` tenta usar GPU se existir e, caso contr√°rio, usa CPU automaticamente.
* `HF_TOKEN` √© opcional. Se n√£o estiver configurado (ou se falhar), o script deve finalizar **sem travar**, gerando as sa√≠das com fallback.

## 5) Sa√≠das esperadas ap√≥s a etapa 01

Ap√≥s rodar, voc√™ deve ver:

* `arquivos_transcritos/txt/` com arquivos `.txt`
* `arquivos_transcritos/json/` com arquivos `.json`

Checklist:

* Existe `arquivos_transcritos/txt/<nome_do_audio>.txt`
* Existe `arquivos_transcritos/json/<nome_do_audio>.json`

---

# üîê Diariza√ß√£o opcional com pyannote (HF_TOKEN)

A diariza√ß√£o (separa√ß√£o de falas por participantes) √© opcional e depende do `HF_TOKEN` e do aceite dos termos do modelo no Hugging Face.

## 1) Criar conta no Hugging Face

Acesse:
[https://huggingface.co/](https://huggingface.co/)

Crie uma conta e fa√ßa login.

## 2) Gerar um Access Token (HF_TOKEN)

Acesse a p√°gina oficial de tokens:
[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

Crie um token e copie o valor.

## 3) Aceitar os termos do modelo pyannote

A diariza√ß√£o depende do modelo:
[https://huggingface.co/pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)

Ao acessar essa p√°gina logado:

* Leia os termos/licen√ßa do modelo
* Clique para aceitar/requisitar acesso, quando o Hugging Face solicitar

Sem esse aceite, o Hugging Face pode bloquear o download (acesso ‚Äúgated‚Äù).

## 4) Configurar HF_TOKEN no PowerShell (tempor√°rio)

Na janela do PowerShell onde voc√™ executar√° o script 01:

```powershell
$env:HF_TOKEN="COLE_AQUI_SEU_TOKEN"
```

Esse m√©todo vale apenas para a janela atual. Ao fechar o PowerShell, a vari√°vel √© perdida.

## 5) Configurar HF_TOKEN permanente no Windows (Vari√°veis de Ambiente)

1. Abra o menu Iniciar e procure por **Editar as vari√°veis de ambiente do sistema**
2. Clique em **Vari√°veis de Ambiente**
3. Em **Vari√°veis do usu√°rio** (ou do sistema, se preferir), clique em **Novo**
4. Defina:

   * Nome da vari√°vel: `HF_TOKEN`
   * Valor da vari√°vel: seu token
5. Confirme e reinicie o PowerShell

## 6) Executar novamente a etapa 01 com HF_TOKEN

Com o token configurado, execute novamente o 01 normalmente.
Se o modelo estiver autorizado, a diariza√ß√£o ser√° tentada automaticamente.

---

## Erros comuns (HF_TOKEN / pyannote)

### 1) HF_TOKEN ausente

Sintoma:

* O script executa e gera as sa√≠das, mas n√£o realiza diariza√ß√£o.

A√ß√£o:

* Defina `HF_TOKEN` e tente novamente.

### 2) Acesso gated n√£o aceito (termos n√£o aceitos)

Sintoma:

* Erros relacionados a acesso negado no download do modelo.

A√ß√£o:

* Acesse a p√°gina do modelo e aceite/requisite acesso:
  [https://huggingface.co/pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)

### 3) Token inv√°lido

Sintoma:

* Erros indicando falha de autentica√ß√£o.

A√ß√£o:

* Gere um novo token:
  [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
* Atualize o `HF_TOKEN` no PowerShell ou nas vari√°veis do Windows.

### 4) pyannote retornando ‚Äúsingle speaker‚Äù

Sintoma:

* A diariza√ß√£o indica apenas um participante, ou o resultado final concentra falas em um √∫nico papel.

Contexto:

* Isso pode ocorrer em √°udios curtos, com falas sobrepostas, baixa qualidade, ou quando o diarizador n√£o separa corretamente e em chats de ia.

Comportamento esperado do projeto:

* O script deve **continuar sem travar** e gerar sa√≠das em modo fallback quando a diariza√ß√£o n√£o for considerada confi√°vel.

---

# üü© Etapa 02 ‚Äî An√°lise SPIN Zero-Shot via Ollama (scripts_base/02_zeroshot.py)

A etapa 02 l√™ os TXT gerados pela etapa 01 e produz planilhas Excel com o resultado da an√°lise SPIN.

Pr√©-requisito obrigat√≥rio:

* O Ollama deve estar ativo na m√°quina com:

```powershell
ollama serve
```

## 1) Criar e ativar o ambiente do zero-shot

Na pasta do projeto:

```powershell
py -3.11 -m venv .venv_zeroshot
.\.venv_zeroshot\Scripts\Activate.ps1
python -m pip install -U pip setuptools wheel
```

## 2) Instalar depend√™ncias do zero-shot

```powershell
python -m pip install -r requirements\requirements_zero_shot.txt
```

## 3) Executar a an√°lise SPIN (exemplo PowerShell)

Exemplo usando os caminhos padr√£o do projeto (entrada em `arquivos_transcritos/txt` e sa√≠da em `saida_excel`):

```powershell
$env:OLLAMA_MODEL="qwen2.5:14b-instruct-q4_K_M"

python .\scripts_base\02_zeroshot.py `
  --in_dir ".\arquivos_transcritos\txt" `
  --out_dir ".\saida_excel" `
  --pattern "*.txt" `
  --recursive true `
  --workers 1
```

Observa√ß√µes:

* O script 02 l√™ prompts a partir de arquivos em `assets/`:

  * `assets/Command_Core_D_Check_V2_6.txt`

## 4) Sa√≠das esperadas ap√≥s a etapa 02

Ap√≥s rodar, voc√™ deve ver:

* `saida_excel/` contendo arquivos Excel gerados para cada transcri√ß√£o (por exemplo: `*_SPIN.xlsx`)

Checklist:

* Existe a pasta `saida_excel/`
* H√° arquivos `*_SPIN.xlsx` compat√≠veis com os TXT processados

---

## Seguran√ßa e √âtica de Dados

* √Åudios n√£o s√£o armazenados permanentemente
* Transcri√ß√µes s√£o tempor√°rias
* Nenhum dado sens√≠vel √© persistido
* Foco exclusivo em m√©tricas agregadas e avalia√ß√£o metodol√≥gica

---

## Cr√©ditos e Autoria

### Realiza√ß√£o Acad√™mica

**Mestrado Acad√™mico em Administra√ß√£o ‚Äî Universidade Feevale**
Linha de Pesquisa: Inova√ß√£o para Competitividade

### Equipe

* **Autor:** [Paulo Luis Fernandes Coutinho](https://github.com/pfcout)
* **Orientadora:** Prof.¬™ Dr.¬™ Cristiane Froehlich
* **Coorientadora:** Prof.¬™ Dr.¬™ Maria Cristina Bohnenberger
* **Colabora√ß√£o T√©cnica:** [Lucas Gabriel Ferreira Gomes (Cientista de Dados)](https://github.com/Oreki820)

### Inspira√ß√£o T√©cnica

Inspirado no motor Zero-Shot de
**Lucas Schwarz** ‚Äî [https://github.com/TheLucasSchwarz/zeroshotENGINE](https://github.com/TheLucasSchwarz/zeroshotENGINE)

---

## Licen√ßa

Apache License 2.0
Uso acad√™mico e profissional permitido, mantendo os devidos cr√©ditos.

---

## Considera√ß√µes Finais

Este reposit√≥rio foi estruturado para:

* disserta√ß√µes e pesquisas aplicadas
* auditoria metodol√≥gica
* avalia√ß√£o profissional de vendas consultivas
* reprodutibilidade acad√™mica

Sugest√µes podem ser discutidas via **Issues**.
